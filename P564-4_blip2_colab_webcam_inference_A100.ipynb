# ✅ YOLO + BLIP-2 + LoRA + Webcam 推理腳本 (for Colab A100)

!pip install -U ultralytics
!pip install transformers accelerate peft bitsandbytes

from PIL import Image
import torch
from ultralytics import YOLO
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from peft import PeftModel, PeftConfig
import os
import cv2
import numpy as np

# ========== Google Drive 掛載 ==========
from google.colab import drive
drive.mount('/content/drive')

# ========== 設定路徑 ==========
yolo_model_path = "/content/drive/MyDrive/project-ai/yolo_model/best.pt"
blip_model_path = "/content/drive/MyDrive/project-ai/blip2_lora_output/checkpoint-60"

# ========== 設定裝置 ==========
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

# ========== 載入模型 ==========
print("📦 加載 YOLOv8 模型...")
yolo_model = YOLO(yolo_model_path)

print("🧠 加載 BLIP-2 + LoRA 模型...")
processor = Blip2Processor.from_pretrained("Salesforce/blip2-opt-2.7b", use_fast=True)
peft_config = PeftConfig.from_pretrained(blip_model_path)
base_model = Blip2ForConditionalGeneration.from_pretrained(
    peft_config.base_model_name_or_path,
    torch_dtype=torch_dtype,
).to(device)
model = PeftModel.from_pretrained(base_model, blip_model_path).to(device)

# ========== 啟用 Colab Webcam ==========
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
from io import BytesIO

def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
      async function takePhoto(quality) {
        const div = document.createElement('div');
        const capture = document.createElement('button');
        capture.textContent = '📷 Capture';
        div.appendChild(capture);

        const video = document.createElement('video');
        video.style.display = 'block';
        const stream = await navigator.mediaDevices.getUserMedia({video: true});

        document.body.appendChild(div);
        div.appendChild(video);
        video.srcObject = stream;
        await video.play();

        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

        await new Promise((resolve) => capture.onclick = resolve);

        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        canvas.getContext('2d').drawImage(video, 0, 0);
        stream.getTracks().forEach(track => track.stop());
        div.remove();

        return canvas.toDataURL('image/jpeg', quality);
      }
      takePhoto({quality: %s});
    ''' % quality)
    display(js)
    data = eval_js("takePhoto()")
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

# ========== 捕捉照片並進行推理 ==========
photo_path = take_photo()
image = Image.open(photo_path).convert("RGB")
results = yolo_model.predict(photo_path, conf=0.5, verbose=False)
boxes = results[0].boxes

if boxes is not None and len(boxes.cls) > 0:
    for i in range(len(boxes.cls)):
        x1, y1, x2, y2 = map(int, boxes.xyxy[i].tolist())
        crop = image.crop((x1, y1, x2, y2))

        try:
            inputs = processor(images=crop, return_tensors="pt").to(device)
            out = model.generate(**inputs, max_new_tokens=32)
            caption = processor.decode(out[0], skip_special_tokens=True)
        except Exception as e:
            caption = "❌ 推理失敗：" + str(e)

        print(f"物件 {i+1}: {caption}")
else:
    print("❗ 未偵測到物件")
